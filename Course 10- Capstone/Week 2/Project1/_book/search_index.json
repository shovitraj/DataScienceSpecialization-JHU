[
["intro.html", "Capstone: Milestone Report Chapter 1 Introduction", " Capstone: Milestone Report Shovit Bhari 2020-07-12 Chapter 1 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 1. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 4. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["introduction.html", "Chapter 2 Introduction", " Chapter 2 Introduction "],
["intrduction.html", "Chapter 3 Intrduction:", " Chapter 3 Intrduction: This is a milestone report which is a part of the Capstone Project in the Data Science Specialization offered by Johns Hopking University in Coursera.org. Tha main objective of this report is to develop an understanding of statistical properties of the data set which can be applied to Natural Language Processing in order to build a predictive text application. This application will scan a stream of text as it is typed by the user an suggest the next possible word to be appended to the input stream. The final product will be used in a Shiny application platform, which will allow the users to type an input text and suggest the next text prediction in a web based environment. The text data can be downloaded here and is provided in four different languages. We will be using English corpora. The model will be trained using a document corpus compiled from the follwing three sources of text data: * Blogs * Twitter * News "],
["methods.html", "Chapter 4 Methods", " Chapter 4 Methods We describe our methods in this chapter. "]
]
